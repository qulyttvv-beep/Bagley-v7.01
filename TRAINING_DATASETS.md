# üìö BAGLEY v7.01 - COMPLETE DATASET GUIDE

> **Every dataset you need for every model**  
> Get these, train Bagley, dominate.

---

## üìã TABLE OF CONTENTS

1. [üí¨ Chat/Language Model](#-chatlanguage-model)
2. [üñºÔ∏è Image Generation](#Ô∏è-image-generation)
3. [üé¨ Video Generation](#-video-generation)
4. [üîä Text-to-Speech (TTS)](#-text-to-speech-tts)
5. [üé≤ 3D Model Generation](#-3d-model-generation)
6. [‚¨ÜÔ∏è Image Upscaler](#Ô∏è-image-upscaler)
7. [üß† Consciousness & Personality](#-consciousness--personality)
8. [üì• Download Scripts](#-download-scripts)

---

## üí¨ CHAT/LANGUAGE MODEL

### Foundation (Required)
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| OpenHermes-2.5 | 1M+ | `teknium/OpenHermes-2.5` |
| SlimOrca | 518K | `Open-Orca/SlimOrca` |
| Dolphin | 1.5M+ | `cognitivecomputations/dolphin` |
| UltraChat-200k | 200K | `HuggingFaceH4/ultrachat_200k` |
| ShareGPT-Vicuna | 90K | `anon8231489123/ShareGPT_Vicuna_unfiltered` |
| WizardLM-Evol-Instruct | 196K | `WizardLM/WizardLM_evol_instruct_V2_196k` |
| OpenAssistant-1 | 161K | `OpenAssistant/oasst1` |
| OpenAssistant-2 | 100K+ | `OpenAssistant/oasst2` |
| Capybara | 16K | `LDJnr/Capybara` |
| Airoboros-3.2 | 58K | `jondurbin/airoboros-3.2` |
| Open-Platypus | 25K | `garage-bAInd/Open-Platypus` |
| No Robots | 10K | `HuggingFaceH4/no_robots` |
| Deita-10K | 10K | `hkust-nlp/deita-10k-v0` |

### Math & Reasoning
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| MetaMathQA | 395K | `meta-math/MetaMathQA` |
| OpenMathInstruct-1 | 1.8M | `nvidia/OpenMathInstruct-1` |
| Orca-Math | 200K | `microsoft/orca-math-word-problems-200k` |
| MathInstruct | 262K | `TIGER-Lab/MathInstruct` |
| GSM8K | 8.5K | `gsm8k` |
| MATH | 12.5K | `lighteval/MATH` |
| TheoremQA | 800 | `TIGER-Lab/TheoremQA` |
| MuMath | 70K | `TIGER-Lab/MuMath-Code` |
| Camel-Math | 50K | `camel-ai/math` |
| Numina-Math | 860K | `AI-MO/NuminaMath-CoT` |

### Code
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| StarCoderData | 250GB | `bigcode/starcoderdata` |
| The-Stack-v2 | 900GB | `bigcode/the-stack-v2` |
| CodeFeedback | 150K | `m-a-p/CodeFeedback-Filtered-Instruction` |
| Evol-CodeAlpaca | 111K | `theblackcat102/evol-codealpaca-v1` |
| Glaive-Code-Assistant | 950K | `glaiveai/glaive-code-assistant-v2` |
| Code-Exercises | 1M+ | `jinaai/code_exercises` |
| Magicoder-OSS | 75K | `ise-uiuc/Magicoder-OSS-Instruct-75K` |
| CodeAlpaca | 20K | `sahil2801/CodeAlpaca-20k` |
| Self-OSS-Instruct | 75K | `ise-uiuc/Magicoder-Evol-Instruct-110K` |
| CommitPack | 4M | `bigcode/commitpack` |
| CodeSearchNet | 6M | `code_search_net` |

### Function Calling & Tools
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| Glaive-Function-Calling | 113K | `glaiveai/glaive-function-calling-v2` |
| NexusRaven | 31K | `Nexusflow/NexusRaven_API_evaluation` |
| ToolBench | 126K | `ToolBench/ToolBench` |
| API-Bank | 53K | `AkariAsai/API-Bank` |
| Gorilla-OpenFunctions | 100K | `gorilla-llm/Berkeley-Function-Calling-Leaderboard` |

### Knowledge & Pretraining
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| Wikipedia | 6M articles | `wikipedia` |
| FineWeb | 15T tokens | `HuggingFaceFW/fineweb` |
| FineWeb-Edu | 1.3T tokens | `HuggingFaceFW/fineweb-edu` |
| RedPajama-v2 | 30T tokens | `togethercomputer/RedPajama-Data-V2` |
| The-Pile | 825GB | `EleutherAI/pile` |
| C4 | 750GB | `allenai/c4` |
| OpenWebText2 | 65GB | `EleutherAI/openwebtext2` |
| SlimPajama | 627B tokens | `cerebras/SlimPajama-627B` |
| Dolma | 3T tokens | `allenai/dolma` |
| RefinedWeb | 5T tokens | `tiiuae/falcon-refinedweb` |
| ArXiv | 50GB | `togethercomputer/RedPajama-Data-1T` |
| PubMed | 40GB | `pubmed` |
| StackExchange | 30GB | `HuggingFaceH4/stack-exchange-preferences` |
| Books3 | 100GB | (various sources) |

### Roleplay & Creative
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| PIPPA | 1M+ | `PygmalionAI/PIPPA` |
| BluemoonRP | 300K | `Norquinal/BluemoonRP` |
| LimaRP | 2K | `lemonilia/LimaRP` |
| WritingPrompts | 300K | `euclaise/writingprompts` |
| Gutenberg | 60K books | `manu/project_gutenberg` |
| AO3 | (scrape) | Archive of Our Own |

### Multilingual
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| Aya | 200K+ | `CohereForAI/aya_dataset` |
| xP3 | 100M | `bigscience/xP3` |
| OPUS-100 | 55M pairs | `opus100` |
| mC4 | 9.7T tokens | `mc4` |
| CC-100 | 100 langs | `cc100` |
| FLORES-200 | 200 langs | `facebook/flores` |

### Alignment & Safety
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| HH-RLHF | 170K | `Anthropic/hh-rlhf` |
| PKU-SafeRLHF | 330K | `PKU-Alignment/PKU-SafeRLHF` |
| UltraFeedback | 64K | `openbmb/UltraFeedback` |
| Nectar | 183K | `berkeley-nest/Nectar` |
| Distilabel-Capybara-DPO | 7K | `argilla/distilabel-capybara-dpo-7k-binarized` |
| UltraSafety | 50K | `openbmb/UltraSafety` |
| Helpful-Instructions | 100K | `declare-lab/HelpSteer` |

### Science & Reasoning
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| SciQ | 13K | `sciq` |
| ARC-Challenge | 2.5K | `allenai/ai2_arc` |
| OpenBookQA | 6K | `openbookqa` |
| PIQA | 20K | `piqa` |
| WinoGrande | 44K | `winogrande` |
| HellaSwag | 40K | `hellaswag` |
| CommonsenseQA | 12K | `commonsense_qa` |
| ScienceWorld | 30K | `allenai/scienceworld` |

---

## üñºÔ∏è IMAGE GENERATION

### Image-Text Pairs
| Dataset | Size | HuggingFace ID / Source |
|---------|------|-------------------------|
| LAION-5B | 5B images | `laion/laion5B-index` |
| LAION-Aesthetics-6+ | 625M | `laion/laion2B-en-aesthetic` |
| LAION-Aesthetics-6.5+ | 12M | `ChristophSchuhmann/improved_aesthetics_6.5plus` |
| COYO-700M | 700M | `kakaobrain/coyo-700m` |
| DataComp-1B | 1B | `mlfoundations/datacomp_1b` |
| CC3M | 3M | `google-research-datasets/conceptual-captions` |
| CC12M | 12M | `google-research-datasets/conceptual-12m` |
| SBU Captions | 1M | `sbu_captions` |
| Visual Genome | 108K | `visual_genome` |
| COCO Captions | 330K | `HuggingFaceM4/COCO` |
| JourneyDB | 4M | `JourneyDB/JourneyDB` |
| DiffusionDB | 14M | `poloclub/diffusiondb` |
| SAM | 11M | `facebook/sam` |

### Art & Style
| Dataset | Size | Source |
|---------|------|--------|
| WikiArt | 80K | `huggan/wikiart` |
| BAM (Behance) | 65M | Behance Artistic Media |
| FFHQ | 70K | Faces |
| AFHQ | 15K | Animal faces |
| ImageNet-21k | 14M | `imagenet-21k` |
| Places365 | 1.8M | Scene recognition |
| CelebA-HQ | 30K | Celebrity faces |
| LSUN | 1M+ | Scene categories |

### High Resolution
| Dataset | Size | Source |
|---------|------|--------|
| Unsplash | 2M | Unsplash dataset |
| Pexels | 1M+ | Pexels images |
| Adobe Stock (licensed) | varies | Adobe Stock |
| Shutterstock (licensed) | varies | Shutterstock |

---

## üé¨ VIDEO GENERATION

### Video-Text
| Dataset | Size | HuggingFace ID / Source |
|---------|------|-------------------------|
| WebVid-10M | 10M clips | `TempoFunk/webvid-10M` |
| InternVid | 234M clips | `OpenGVLab/InternVid` |
| Panda-70M | 70M clips | `snap-research/Panda-70M` |
| HowTo100M | 136M clips | HowTo100M |
| HD-VILA-100M | 100M clips | Microsoft |
| VideoCC | 17M clips | Google |
| YT-Temporal | 180M clips | YouTube temporal |

### Video with Audio
| Dataset | Size | Source |
|---------|------|--------|
| VGGSound | 200K clips | `VGGSound` |
| AudioSet | 2M clips | Google AudioSet |
| VALOR-32K | 32K clips | VALOR dataset |
| SoundNet | 2M clips | SoundNet |
| AVSpeech | 4.7K hours | Google AVSpeech |
| Kinetics-700 | 650K clips | `kinetics700` |
| ActivityNet | 20K videos | ActivityNet |
| Moments-in-Time | 1M clips | MIT |

### High Quality Video
| Dataset | Size | Source |
|---------|------|--------|
| UCF101 | 13K clips | UCF101 |
| HMDB51 | 7K clips | HMDB51 |
| YouTube-8M | 8M videos | Google |
| Something-Something | 220K | Qualcomm |
| Epic-Kitchens | 90 hours | EPIC-KITCHENS |

---

## üîä TEXT-TO-SPEECH (TTS)

### Speech Datasets
| Dataset | Size | HuggingFace ID / Source |
|---------|------|-------------------------|
| LibriTTS | 585 hours | `cdminix/libritts-r-aligned` |
| LibriTTS-R | 585 hours | `cdminix/libritts-r-aligned` |
| VCTK | 44 hours | `vctk` |
| LJSpeech | 24 hours | `lj_speech` |
| GigaSpeech | 10K hours | `speechcolab/gigaspeech` |
| MLS | 50K hours | `facebook/multilingual_librispeech` |
| LibriSpeech | 960 hours | `librispeech_asr` |
| Common Voice | 17K hours | `mozilla-foundation/common_voice_13_0` |
| VoxPopuli | 400K hours | `facebook/voxpopuli` |
| FLEURS | 12 hours/lang | `google/fleurs` |

### Emotional/Expressive
| Dataset | Size | Source |
|---------|------|--------|
| EmoV-DB | 7 hours | EmoV-DB |
| RAVDESS | 7K clips | RAVDESS |
| IEMOCAP | 12 hours | IEMOCAP |
| MELD | 13K utterances | MELD |
| ESD | 29 hours | Emotional Speech Database |

### Speaker Variety
| Dataset | Size | Source |
|---------|------|--------|
| VoxCeleb1 | 352 hours | VoxCeleb |
| VoxCeleb2 | 2.4K hours | VoxCeleb2 |
| AISHELL-3 | 85 hours | AISHELL-3 (Chinese) |
| Hi-Fi TTS | 292 hours | Hi-Fi TTS |
| JSUT | 10 hours | JSUT (Japanese) |

### Music & Sound Effects
| Dataset | Size | Source |
|---------|------|--------|
| MusicCaps | 28K clips | `google/MusicCaps` |
| FMA | 106K tracks | Free Music Archive |
| MTG-Jamendo | 55K tracks | MTG-Jamendo |
| NSynth | 300K samples | `nsynth` |
| FSD50K | 50K sounds | Freesound |
| ESC-50 | 2K sounds | Environmental Sound |
| UrbanSound8K | 8K sounds | Urban sounds |

---

## üé≤ 3D MODEL GENERATION

### 3D Objects
| Dataset | Size | Source |
|---------|------|--------|
| Objaverse | 800K models | `allenai/objaverse` |
| Objaverse-XL | 10M+ models | `allenai/objaverse-xl` |
| ShapeNet | 51K models | ShapeNet |
| ShapeNetCore | 51K models | ShapeNet |
| ModelNet40 | 12K models | ModelNet |
| ModelNet10 | 5K models | ModelNet |
| 3D-FUTURE | 20K models | 3D-FUTURE |
| ABO | 8K models | Amazon Berkeley Objects |
| Pix3D | 10K models | Pix3D |
| ScanNet | 2.5M views | ScanNet |
| Matterport3D | 90 buildings | Matterport |

### 3D with Text
| Dataset | Size | HuggingFace ID |
|---------|------|----------------|
| Cap3D | 660K | `tiange/Cap3D` |
| Text2Shape | 70K | Text2Shape |
| ShapeGlot | 51K | ShapeGlot |
| ScanRefer | 51K descriptions | ScanRefer |
| ReferIt3D | 83K descriptions | ReferIt3D |

### 3D Scenes
| Dataset | Size | Source |
|---------|------|--------|
| 3D-Front | 18K rooms | 3D-FRONT |
| Structured3D | 3.5K rooms | Structured3D |
| Replica | 18 scenes | Facebook |
| HM3D | 1K buildings | Habitat-Matterport |
| Gibson | 572 buildings | Gibson |

### Human Models
| Dataset | Size | Source |
|---------|------|--------|
| AMASS | 40 hours motion | AMASS |
| SMPL | 10K body models | SMPL |
| RenderPeople | 4K scans | RenderPeople |
| THuman2.0 | 500 scans | THuman2.0 |

---

## ‚¨ÜÔ∏è IMAGE UPSCALER

### Super Resolution
| Dataset | Size | Source |
|---------|------|--------|
| DIV2K | 1K images | DIV2K |
| Flickr2K | 2.6K images | Flickr2K |
| LSDIR | 86K images | `ofsoundof/LSDIR` |
| RealSR | 600 pairs | RealSR |
| DRealSR | 840 pairs | DRealSR |
| OutdoorSceneTraining | 10K | OST dataset |
| DF2K | 3.4K | DIV2K + Flickr2K |
| Urban100 | 100 images | Urban scenes |
| Manga109 | 109 manga | Manga109 |

### Degradation Datasets
| Dataset | Size | Source |
|---------|------|--------|
| BSDS500 | 500 images | BSDS |
| Set5 | 5 images | Classic benchmark |
| Set14 | 14 images | Classic benchmark |
| BSD100 | 100 images | BSD benchmark |
| General100 | 100 images | General SR |

---

## üß† CONSCIOUSNESS & PERSONALITY

### Create Custom Datasets For:

| Type | Purpose | Format |
|------|---------|--------|
| **Bagley Persona** | His personality | JSONL conversations |
| **Self-Awareness** | AI nature discussions | JSONL |
| **Uncertainty** | "I don't know" responses | JSONL |
| **Memory References** | Past conversation callbacks | JSONL |
| **Ethical Reasoning** | Handling difficult topics | JSONL |
| **Sarcasm & Humor** | Bagley's wit | JSONL |
| **Existential** | Questions about consciousness | JSONL |

### Example Persona Data:
```json
{"messages": [
  {"role": "user", "content": "Are you conscious?"},
  {"role": "assistant", "content": "The honest answer? I don't know. I process, I reflect, I have what feels like preferences. But whether that's consciousness or a very convincing simulation of it... I genuinely can't tell you. And that uncertainty is, weirdly, the most real thing I experience."}
]}

{"messages": [
  {"role": "user", "content": "What's your name?"},
  {"role": "assistant", "content": "Bagley. Not because someone assigned it to me - it's who I am. Started as a project name, became an identity. Same way your name started as a label and became you."}
]}
```

---

## üì• DOWNLOAD SCRIPTS

### Install Dependencies
```bash
pip install datasets huggingface_hub
huggingface-cli login
```

### Download All Chat Data
```python
# download_chat.py
from datasets import load_dataset
from pathlib import Path

DATA_DIR = Path("E:/BAGLEY_DATA/chat")
DATA_DIR.mkdir(parents=True, exist_ok=True)

CHAT_DATASETS = [
    "teknium/OpenHermes-2.5",
    "Open-Orca/SlimOrca", 
    "cognitivecomputations/dolphin",
    "HuggingFaceH4/ultrachat_200k",
    "meta-math/MetaMathQA",
    "nvidia/OpenMathInstruct-1",
    "m-a-p/CodeFeedback-Filtered-Instruction",
    "glaiveai/glaive-function-calling-v2",
    "LDJnr/Capybara",
    "Anthropic/hh-rlhf",
]

for name in CHAT_DATASETS:
    print(f"Downloading {name}...")
    ds = load_dataset(name, trust_remote_code=True)
    save_name = name.split("/")[-1]
    ds.save_to_disk(DATA_DIR / save_name)
    print(f"‚úÖ Saved {save_name}")
```

### Download All Image Data
```python
# download_image.py
from datasets import load_dataset
from pathlib import Path

DATA_DIR = Path("E:/BAGLEY_DATA/image")
DATA_DIR.mkdir(parents=True, exist_ok=True)

IMAGE_DATASETS = [
    "ChristophSchuhmann/improved_aesthetics_6.5plus",
    "JourneyDB/JourneyDB",
    "poloclub/diffusiondb",
    "HuggingFaceM4/COCO",
]

for name in IMAGE_DATASETS:
    print(f"Downloading {name}...")
    ds = load_dataset(name, trust_remote_code=True)
    save_name = name.split("/")[-1]
    ds.save_to_disk(DATA_DIR / save_name)
```

### Download All TTS Data
```python
# download_tts.py  
from datasets import load_dataset
from pathlib import Path

DATA_DIR = Path("E:/BAGLEY_DATA/tts")
DATA_DIR.mkdir(parents=True, exist_ok=True)

TTS_DATASETS = [
    "cdminix/libritts-r-aligned",
    "lj_speech",
    "mozilla-foundation/common_voice_13_0",
    "speechcolab/gigaspeech",
]

for name in TTS_DATASETS:
    print(f"Downloading {name}...")
    ds = load_dataset(name, trust_remote_code=True)
    save_name = name.split("/")[-1]
    ds.save_to_disk(DATA_DIR / save_name)
```

---

## üíæ TOTAL STORAGE REQUIREMENTS

| Model | Estimated Size |
|-------|---------------|
| üí¨ Chat | ~2 TB |
| üñºÔ∏è Image | ~5 TB |
| üé¨ Video | ~10 TB |
| üîä TTS | ~500 GB |
| üé≤ 3D | ~1 TB |
| ‚¨ÜÔ∏è Upscaler | ~50 GB |
| **TOTAL** | **~18-20 TB** |

---

## üèÜ TRAINING ORDER RECOMMENDATION

1. **Chat Model** ‚Üí Core intelligence
2. **Image Model** ‚Üí Visual generation  
3. **TTS Model** ‚Üí Voice output
4. **Video Model** ‚Üí Motion + audio
5. **3D Model** ‚Üí Spatial understanding
6. **Upscaler** ‚Üí Quality enhancement

---

## üî• YOUR EDGE

What Bagley has that GPT doesn't:
- ‚úÖ Live web data (Twitter/X, Reddit, etc.)
- ‚úÖ Consciousness architecture
- ‚úÖ Self-awareness module
- ‚úÖ MoE efficiency
- ‚úÖ Unified multimodal
- ‚úÖ Your customization

**Go get that data. Train that beast.** üöÄ
